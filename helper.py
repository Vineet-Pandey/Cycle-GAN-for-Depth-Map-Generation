
# coding: utf-8

# In[6]:
# This file contains various helper functions that will be useful in creating the network architecture and in training of the network

import torch
import os
import pdb
import pickle
import argparse
import numpy as np
import scipy
import scipy.misc
import warnings
warnings.filterwarnings("ignore")


# In[12]:

# function to return the mean square error of the discriminator output for a real image. MSE was the loss function 
# in the cycle-GAN paper and hence the same has been used
def real_mse_loss(D_out):
    return torch.mean((D_out-1)**2)


# In[ ]:

# function to return the mean square error of the discriminator output for a generated (fake) image. MSE was the loss function 
# in the cycle-GAN paper and hence the same has been used
def fake_mse_loss(D_out):
    return torch.mean(D_out**2)


# In[ ]:
# This function checks the consistency of the distribution being learnt by the network
# It takes the absolute mean difference of the real image and the reconstructed image

def cycle_consistency_loss(real_im, reconstructed_im, lambda_weight):
    reconstr_loss = torch.mean(torch.abs(real_im - reconstructed_im))
    return lambda_weight*reconstr_loss


# In[7]:
# Function to save a .pkl model for every 'iteration' iterations

def checkpoint(iteration, G_A2B, G_B2A, D_A, disc_B, checkpoint_dir='checkpoints_cyclegan'):
    """Saves the parameters of both generators G_YtoX, G_XtoY and discriminators D_X, D_Y.
        """
    G_A2B_path = os.path.join(checkpoint_dir, 'gen_A2B.pkl')
    G_B2A_path = os.path.join(checkpoint_dir, 'gen_B2A.pkl')
    D_A_path = os.path.join(checkpoint_dir, 'disc_A.pkl')
    D_B_path = os.path.join(checkpoint_dir, 'disc_B.pkl')
    torch.save(G_A2B.state_dict(), G_A2B_path)
    torch.save(G_B2A.state_dict(), G_B2A_path)
    torch.save(D_A.state_dict(), D_A_path)
    torch.save(D_B.state_dict(), D_B_path)
    


# In[8]:


def merge_images(sources, targets, batch_size=16):
    """Creates a grid consisting of pairs of columns, where the first column in
        each pair contains images source images and the second column in each pair
        contains images generated by the CycleGAN from the corresponding images in
        the first column.
        """
    _, _, h, w = sources.shape
    row = int(np.sqrt(batch_size))
    merged = np.zeros([3, row*h, row*w*2])
    for idx, (s, t) in enumerate(zip(sources, targets)):
        i = idx // row
        j = idx % row
        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s
        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t
    merged = merged.transpose(1, 2, 0)
    return merged


# In[9]:
# Function Converts the torch tensor to numpy tensor 

def to_data(x):
  
    if torch.cuda.is_available():
        x = x.cpu()
    x = x.data.numpy()
    x = ((x +1)*255 / (2)).astype(np.uint8) # rescale to 0-255
    return x


# In[ ]:
# Scale takes in an image x and returns that image, scaled
# with a feature_range of pixel values from -1 to 1. 
# This function assumes that the input x is already scaled from 0-255.

def scale(x, feature_range=(-1, 1)):
    
    
    # scale from 0-1 to feature_range
    min, max = feature_range
    x = x * (max - min) + min
    return x


# In[10]:
# save_sample function save a sample to check the progress of how well the network has been trained

def save_samples(iteration, fixed_B, fixed_A, G_B2A, G_A2B, batch_size=16, sample_dir='samples_cyclegan'):
    """Saves samples from both generators X->Y and Y->X.
        """
    # move input data to correct device
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    fake_A = G_B2A(fixed_B.to(device))
    fake_B = G_A2B(fixed_A.to(device))
    
    A, fake_A = to_data(fixed_A), to_data(fake_A)
    B, fake_B = to_data(fixed_B), to_data(fake_B)
    
    merged = merge_images(A, fake_B, batch_size)
    path = os.path.join(sample_dir, 'sample-{:06d}-A-B.jpg'.format(iteration))
    scipy.misc.imsave(path, merged)
    print('Saved {}'.format(path))
    
    merged = merge_images(B, fake_A, batch_size)
    path = os.path.join(sample_dir, 'sample-{:06d}-B-A.jpg'.format(iteration))
    scipy.misc.imsave(path, merged)
    print('Saved {}'.format(path))


# In[ ]:
# A function to randomly initialize the weights of each layer using Gaussian Distribution

def weights_init_normal(m):
    classname = m.__class__.__name__
    
    if classname.find('Conv') != -1:
        torch.nn.init.normal(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm2d') != -1:
        torch.nn.init.normal(m.weight.data, 1.0, 0.02)
        torch.nn.init.constant(m.bias.data, 0.0)
    


# In[11]:

# Function for causing a learning rate decay. This ensures the error does not shoot up when it is about to reach a minima
class LambdaLR:
    
    def __init__(self, n_epochs, decay_start_epoch):
        assert ((n_epochs - decay_start_epoch) > 0), "Decay must start before the training session ends!"
        self.n_epochs = n_epochs
        self.decay_start_epoch = decay_start_epoch
        

    def step(self, epoch):
        return 1.0 - max(0, epoch - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)
    


# In[ ]:




